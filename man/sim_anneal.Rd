% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/numerical_mle.R
\name{sim_anneal}
\alias{sim_anneal}
\title{sim_anneal}
\usage{
sim_anneal(f, x0, options = list(), ...)
}
\arguments{
\item{f}{Objective function to maximize, `f : R^d -> R`}

\item{x0}{Initial guess}

\item{options}{List of options
* `t_init` Initial temperature
* `t_end` Final temperature
* `alpha` Cooling factor
* `iter_per_temp` Number of iterations per temperature
* `max_iter` Maximum number of iterations, used instead of t_end
            if not NULL, defaults to NULL
* `debug` If TRUE, print debugging information to the console
* `trace` If TRUE, track the history of positions and values
* `sup` Support function, returns TRUE if x is in the domain of f
* `neigh` Neighborhood function, returns a random neighbor of x
* `...` Additional arguments to neigh}
}
\value{
list with best solution (argmax) and its corresponding
        objective function value (max), and optionally path
}
\description{
This function implements the simulated annealing algorithm,
which is a global optimization algorithm that is useful for
finding a good starting point for a local optimization algorithm.
We do not return this as an MLE object because, to be a good
estimate of the MLE, the gradient of `f` evaluated
at its solution should be close to zero, assuming the MLE
is interior to the domain of `f`. However, since this algorithm
is not guided by gradient information, it is not sensitive to
the gradient of `f` and instead only seeks to maximize `f`.
}
\details{
This also works for discrete optimization problems.
}
