% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/numerical_mle.R
\name{mle_local_search}
\alias{mle_local_search}
\title{mle_local_search}
\usage{
mle_local_search(
  ll,
  theta0,
  dir,
  eps = 1e-05,
  proj = NULL,
  sup = NULL,
  tol = NULL,
  eta = 1,
  max_iter = 0L,
  debug = FALSE
)
}
\arguments{
\item{theta0}{numeric, initial guess, a column vector of size `p`}

\item{dir}{function, promising direction function of type `R^p -> R^p`}

\item{eps}{numeric, tolerance for convergence}

\item{proj}{function, projection function of type `R^p -> R^p`}

\item{sup}{predicate function, domain of support function of type
`R^p -> {TRUE,FALSE}` for the log-likelihood function `l`}

\item{tol}{function, tolerance function of type `R^p -> R`}

\item{eta}{numeric, learning rate, defaults to 1}

\item{max_iter}{integer, maximum number of iterations}

\item{debug}{logical, output debugging information if `TRUE`;
defaults to `FALSE`}

\item{l}{function, log-likelihood function of type `R^p -> R`}
}
\description{
General local search method. It doesn't do anything fancy, but it is
more easily tweakable than `optim` in the `stats` package and can be
made to generate results when `optim` fails.
I use it for debugging and testing, but I also use it to implement
in a more transparent way the local search methods for newton-raphson
and gradient ascent.
}
