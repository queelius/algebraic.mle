<!DOCTYPE html>
<!-- Generated by pkgdown: do not edit by hand --><html lang="en">
<head>
<meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
<meta charset="utf-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<title>Fitting Common Distributions to a DGP ‚Ä¢ algebraic.mle</title>
<script src="../deps/jquery-3.6.0/jquery-3.6.0.min.js"></script><meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<link href="../deps/bootstrap-5.3.1/bootstrap.min.css" rel="stylesheet">
<script src="../deps/bootstrap-5.3.1/bootstrap.bundle.min.js"></script><link href="../deps/font-awesome-6.5.2/css/all.min.css" rel="stylesheet">
<link href="../deps/font-awesome-6.5.2/css/v4-shims.min.css" rel="stylesheet">
<script src="../deps/headroom-0.11.0/headroom.min.js"></script><script src="../deps/headroom-0.11.0/jQuery.headroom.min.js"></script><script src="../deps/bootstrap-toc-1.0.1/bootstrap-toc.min.js"></script><script src="../deps/clipboard.js-2.0.11/clipboard.min.js"></script><script src="../deps/search-1.0.0/autocomplete.jquery.min.js"></script><script src="../deps/search-1.0.0/fuse.min.js"></script><script src="../deps/search-1.0.0/mark.min.js"></script><!-- pkgdown --><script src="../pkgdown.js"></script><meta property="og:title" content="Fitting Common Distributions to a DGP">
</head>
<body>
    <a href="#main" class="visually-hidden-focusable">Skip to contents</a>


    <nav class="navbar navbar-expand-lg fixed-top bg-light" data-bs-theme="light" aria-label="Site navigation"><div class="container">

    <a class="navbar-brand me-2" href="../index.html">algebraic.mle</a>

    <small class="nav-text text-muted me-auto" data-bs-toggle="tooltip" data-bs-placement="bottom" title="">0.9.0</small>


    <button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#navbar" aria-controls="navbar" aria-expanded="false" aria-label="Toggle navigation">
      <span class="navbar-toggler-icon"></span>
    </button>

    <div id="navbar" class="collapse navbar-collapse ms-3">
      <ul class="navbar-nav me-auto">
<li class="nav-item"><a class="nav-link" href="../reference/index.html">Reference</a></li>
<li class="active nav-item dropdown">
  <button class="nav-link dropdown-toggle" type="button" id="dropdown-articles" data-bs-toggle="dropdown" aria-expanded="false" aria-haspopup="true">Articles</button>
  <ul class="dropdown-menu" aria-labelledby="dropdown-articles">
<li><a class="dropdown-item" href="../articles/dgp.html">Dynamic failure rate model</a></li>
    <li><a class="dropdown-item" href="../articles/fitting-common-dist.html">Fitting Common Distributions to a DGP</a></li>
    <li><a class="dropdown-item" href="../articles/statistics.html">Statistics and characteristics of the MLE</a></li>
  </ul>
</li>
      </ul>
<ul class="navbar-nav">
<li class="nav-item"><form class="form-inline" role="search">
 <input class="form-control" type="search" name="search-input" id="search-input" autocomplete="off" aria-label="Search site" placeholder="Search for" data-search-index="../search.json">
</form></li>
<li class="nav-item"><a class="external-link nav-link" href="https://github.com/queelius/algebraic.mle/" aria-label="GitHub"><span class="fa fab fa-github fa-lg"></span></a></li>
      </ul>
</div>


  </div>
</nav><div class="container template-article">




<div class="row">
  <main id="main" class="col-md-9"><div class="page-header">

      <h1>Fitting Common Distributions to a DGP</h1>
            
      
      <small class="dont-index">Source: <a href="https://github.com/queelius/algebraic.mle/blob/master/vignettes/fitting-common-dist.Rmd" class="external-link"><code>vignettes/fitting-common-dist.Rmd</code></a></small>
      <div class="d-none name"><code>fitting-common-dist.Rmd</code></div>
    </div>

    
    
<div class="sourceCode" id="cb1"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="kw"><a href="https://rdrr.io/r/base/library.html" class="external-link">library</a></span><span class="op">(</span><span class="va"><a href="https://github.com/queelius/algebraic.mle" class="external-link">algebraic.mle</a></span><span class="op">)</span></span>
<span><span class="kw"><a href="https://rdrr.io/r/base/library.html" class="external-link">library</a></span><span class="op">(</span><span class="va"><a href="https://github.com/queelius/algebraic.dist" class="external-link">algebraic.dist</a></span><span class="op">)</span></span>
<span><span class="kw"><a href="https://rdrr.io/r/base/library.html" class="external-link">library</a></span><span class="op">(</span><span class="va">boot</span><span class="op">)</span></span></code></pre></div>
<div class="section level2">
<h2 id="introduction">Introduction<a class="anchor" aria-label="anchor" href="#introduction"></a>
</h2>
<p>The goal of this vignette is to demonstrate using the R package
<code>algebraic.mle</code> for inference on maximum likelihood
estimators (MLEs). We will simulate a dataset whose true data generating
process (DGP) is a mixture of Weibull and Normal distributions. However,
we will fit Weibull and Normal distributions separately to the data to
explore which provides a better fit.</p>
</div>
<div class="section level2">
<h2 id="data-simulation">Data Simulation<a class="anchor" aria-label="anchor" href="#data-simulation"></a>
</h2>
<p>First, here are the simulation parameters:</p>
<div class="sourceCode" id="cb2"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">n</span> <span class="op">&lt;-</span> <span class="fl">100</span></span>
<span><span class="va">err</span> <span class="op">&lt;-</span> <span class="fl">0.1</span></span>
<span><span class="va">shape</span> <span class="op">&lt;-</span> <span class="fl">2</span></span>
<span><span class="va">scale</span> <span class="op">&lt;-</span> <span class="fl">10</span></span>
<span><span class="va">theta</span> <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html" class="external-link">c</a></span><span class="op">(</span><span class="va">shape</span>, <span class="va">scale</span><span class="op">)</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/base/Random.html" class="external-link">set.seed</a></span><span class="op">(</span><span class="fl">142334</span><span class="op">)</span></span></code></pre></div>
<p>We simulate a sample of size
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>n</mi><mo>=</mo><mn>100</mn></mrow><annotation encoding="application/x-tex">n = 100</annotation></semantics></math>
from the DGP:
<math display="block" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>T</mi><mi>i</mi></msub><mo>=</mo><msub><mi>W</mi><mi>i</mi></msub><mo>+</mo><msub><mi>œµ</mi><mi>i</mi></msub></mrow><annotation encoding="application/x-tex">
    T_i = W_i + \epsilon_i
</annotation></semantics></math> where
<math display="block" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>W</mi><mi>i</mi></msub><mo>‚àº</mo><mo>Weibull</mo><mrow><mo stretchy="true" form="prefix">(</mo><mi>k</mi><mo>=</mo><mn>2</mn><mo>,</mo><mi>Œª</mi><mo>=</mo><mn>10</mn><mo stretchy="true" form="postfix">)</mo></mrow></mrow><annotation encoding="application/x-tex">
    W_i \sim \operatorname{Weibull}(k = 2, \lambda = 10)
</annotation></semantics></math> and
<math display="block" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>œµ</mi><mi>i</mi></msub><mo>‚àº</mo><mo>normal</mo><mrow><mo stretchy="true" form="prefix">(</mo><mi>Œº</mi><mo>=</mo><mn>0</mn><mo>,</mo><mi>œÉ</mi><mo>=</mo><mn>0.1</mn><mo stretchy="true" form="postfix">)</mo></mrow><mi>.</mi></mrow><annotation encoding="application/x-tex">
    \epsilon_i \sim \operatorname{normal}(\mu = 0, \sigma = 0.1).
</annotation></semantics></math></p>
<p>We can simulate a sample from this DGP mixture distribution using the
<code>rweibull</code> and <code>rnorm</code> functions:</p>
<div class="sourceCode" id="cb3"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">x</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/stats/Weibull.html" class="external-link">rweibull</a></span><span class="op">(</span>n <span class="op">=</span> <span class="va">n</span>, shape <span class="op">=</span> <span class="va">shape</span>, scale <span class="op">=</span> <span class="va">scale</span><span class="op">)</span> <span class="op">+</span></span>
<span>  <span class="fu"><a href="https://rdrr.io/r/stats/Normal.html" class="external-link">rnorm</a></span><span class="op">(</span>n <span class="op">=</span> <span class="va">n</span>, mean <span class="op">=</span> <span class="fl">0</span>, sd <span class="op">=</span> <span class="va">err</span><span class="op">)</span></span></code></pre></div>
</div>
<div class="section level2">
<h2 id="visualizing-data">Visualizing Data<a class="anchor" aria-label="anchor" href="#visualizing-data"></a>
</h2>
<p>Here are some observations:</p>
<div class="sourceCode" id="cb4"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu"><a href="https://rdrr.io/r/utils/head.html" class="external-link">head</a></span><span class="op">(</span><span class="va">x</span>, n <span class="op">=</span> <span class="fl">4</span><span class="op">)</span></span>
<span><span class="co">#&gt; [1]  6.69  2.96 13.05  5.34</span></span></code></pre></div>
<p>Visualizing the data is a good first step in the analysis of the
data. If the data is univariate or bivariate, we can plot a histogram of
the data pretty easily. We show a histogram of the simulated data below:
<img src="fitting-common-dist_files/figure-html/histo-1.png" class="r-plt" width="700" style="display: block; margin: auto;"></p>
</div>
<div class="section level2">
<h2 id="parametrically-modeling-the-data">Parametrically Modeling the Data<a class="anchor" aria-label="anchor" href="#parametrically-modeling-the-data"></a>
</h2>
<p>If we only had this sample, what might we conclude? This can be a
very difficult problem.</p>
<p>If we were only interested in, say, <em>prediction</em>, and we had a
sufficiently large sample, we could use a non-parametric methods and
‚Äúlet the data speak for itself.‚Äù However, if we are interested in
inference (e.g., explaining the data) or the sample was small, then we
usually need to make some assumptions about the data.</p>
<p>In this case, we will assume that the data is drawn from a parametric
distribution. There are many well-known, named parametric distributions,
e.g., Pareto, Weibull, and Normal, to name a few. We will fit the
Weibull and the Normal distributions, and compare the results.</p>
</div>
<div class="section level2">
<h2 id="maximum-likelihood-estimation">Maximum Likelihood Estimation<a class="anchor" aria-label="anchor" href="#maximum-likelihood-estimation"></a>
</h2>
<p>We will use maximum likelihood estimation (MLE) to estimate the
parameters of both the Weibull and the Normal, and then wrap these
estimates into an <code>mle</code> object provided by
<code>algebraic.mle</code> package:</p>
<div class="sourceCode" id="cb5"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">fit_normal</span> <span class="op">&lt;-</span> <span class="kw">function</span><span class="op">(</span><span class="va">data</span><span class="op">)</span> <span class="op">{</span></span>
<span>    <span class="va">loglik</span> <span class="op">&lt;-</span> <span class="kw">function</span><span class="op">(</span><span class="va">theta</span><span class="op">)</span> <span class="op">{</span></span>
<span>        <span class="fu"><a href="https://rdrr.io/r/base/sum.html" class="external-link">sum</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/stats/Normal.html" class="external-link">dnorm</a></span><span class="op">(</span><span class="va">data</span>, mean <span class="op">=</span> <span class="va">theta</span><span class="op">[</span><span class="fl">1</span><span class="op">]</span>, sd <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/MathFun.html" class="external-link">sqrt</a></span><span class="op">(</span><span class="va">theta</span><span class="op">[</span><span class="fl">2</span><span class="op">]</span><span class="op">)</span>, log <span class="op">=</span> <span class="cn">TRUE</span><span class="op">)</span><span class="op">)</span></span>
<span>    <span class="op">}</span></span>
<span>    <span class="va">mu.hat</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/mean.html" class="external-link">mean</a></span><span class="op">(</span><span class="va">data</span><span class="op">)</span></span>
<span>    <span class="va">sigma2.hat</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/mean.html" class="external-link">mean</a></span><span class="op">(</span><span class="op">(</span><span class="va">data</span> <span class="op">-</span> <span class="va">mu.hat</span><span class="op">)</span><span class="op">^</span><span class="fl">2</span><span class="op">)</span></span>
<span>    <span class="va">H</span> <span class="op">&lt;-</span> <span class="op">-</span><span class="fu">numDeriv</span><span class="fu">::</span><span class="fu"><a href="https://rdrr.io/pkg/numDeriv/man/hessian.html" class="external-link">hessian</a></span><span class="op">(</span><span class="va">loglik</span>, <span class="fu"><a href="https://rdrr.io/r/base/c.html" class="external-link">c</a></span><span class="op">(</span><span class="va">mu.hat</span>, <span class="va">sigma2.hat</span><span class="op">)</span><span class="op">)</span></span>
<span>    <span class="fu"><a href="../reference/mle.html">mle</a></span><span class="op">(</span>theta.hat <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html" class="external-link">c</a></span><span class="op">(</span><span class="va">mu.hat</span>, <span class="va">sigma2.hat</span><span class="op">)</span>,</span>
<span>        loglike <span class="op">=</span> <span class="fu">loglik</span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/c.html" class="external-link">c</a></span><span class="op">(</span><span class="va">mu.hat</span>, <span class="va">sigma2.hat</span><span class="op">)</span><span class="op">)</span>,</span>
<span>        score <span class="op">=</span> <span class="fu">numDeriv</span><span class="fu">::</span><span class="fu"><a href="https://rdrr.io/pkg/numDeriv/man/grad.html" class="external-link">grad</a></span><span class="op">(</span><span class="va">loglik</span>, <span class="fu"><a href="https://rdrr.io/r/base/c.html" class="external-link">c</a></span><span class="op">(</span><span class="va">mu.hat</span>, <span class="va">sigma2.hat</span><span class="op">)</span><span class="op">)</span>,</span>
<span>        sigma <span class="op">=</span> <span class="fu">MASS</span><span class="fu">::</span><span class="fu"><a href="https://rdrr.io/pkg/MASS/man/ginv.html" class="external-link">ginv</a></span><span class="op">(</span><span class="va">H</span><span class="op">)</span>,</span>
<span>        info <span class="op">=</span> <span class="va">H</span>,</span>
<span>        obs <span class="op">=</span> <span class="va">data</span>,</span>
<span>        nobs <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/length.html" class="external-link">length</a></span><span class="op">(</span><span class="va">data</span><span class="op">)</span>,</span>
<span>        superclasses <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html" class="external-link">c</a></span><span class="op">(</span><span class="st">"mle_normal"</span><span class="op">)</span><span class="op">)</span></span>
<span><span class="op">}</span></span>
<span></span>
<span><span class="va">fit_weibull</span> <span class="op">&lt;-</span> <span class="kw">function</span><span class="op">(</span><span class="va">data</span><span class="op">)</span> <span class="op">{</span></span>
<span>    <span class="va">loglik</span> <span class="op">&lt;-</span> <span class="kw">function</span><span class="op">(</span><span class="va">theta</span><span class="op">)</span> <span class="op">{</span></span>
<span>        <span class="fu"><a href="https://rdrr.io/r/base/sum.html" class="external-link">sum</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/stats/Weibull.html" class="external-link">dweibull</a></span><span class="op">(</span><span class="va">data</span>, shape <span class="op">=</span> <span class="va">theta</span><span class="op">[</span><span class="fl">1</span><span class="op">]</span>, scale <span class="op">=</span> <span class="va">theta</span><span class="op">[</span><span class="fl">2</span><span class="op">]</span>, log <span class="op">=</span> <span class="cn">TRUE</span><span class="op">)</span><span class="op">)</span></span>
<span>    <span class="op">}</span></span>
<span></span>
<span>    <span class="va">sol</span> <span class="op">&lt;-</span> <span class="fu">stats</span><span class="fu">::</span><span class="fu"><a href="https://rdrr.io/r/stats/optim.html" class="external-link">optim</a></span><span class="op">(</span></span>
<span>        par <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html" class="external-link">c</a></span><span class="op">(</span><span class="va">shape</span>, <span class="va">scale</span><span class="op">)</span>,</span>
<span>        fn <span class="op">=</span> <span class="va">loglik</span>,</span>
<span>        hessian <span class="op">=</span> <span class="cn">TRUE</span>,</span>
<span>        method <span class="op">=</span> <span class="st">"L-BFGS-B"</span>,</span>
<span>        lower <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html" class="external-link">c</a></span><span class="op">(</span><span class="fl">0</span>, <span class="fl">0</span><span class="op">)</span>,</span>
<span>        <span class="co">#method = "Nelder-Mead",</span></span>
<span>        control <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/list.html" class="external-link">list</a></span><span class="op">(</span>maxit <span class="op">=</span> <span class="fl">10000</span>, fnscale <span class="op">=</span> <span class="op">-</span><span class="fl">1</span><span class="op">)</span><span class="op">)</span></span>
<span></span>
<span>    <span class="fu"><a href="../reference/mle.html">mle</a></span><span class="op">(</span>theta.hat <span class="op">=</span> <span class="va">sol</span><span class="op">$</span><span class="va">par</span>,</span>
<span>        loglike <span class="op">=</span> <span class="va">sol</span><span class="op">$</span><span class="va">value</span>,</span>
<span>        sigma <span class="op">=</span> <span class="fu">MASS</span><span class="fu">::</span><span class="fu"><a href="https://rdrr.io/pkg/MASS/man/ginv.html" class="external-link">ginv</a></span><span class="op">(</span><span class="op">-</span><span class="va">sol</span><span class="op">$</span><span class="va">hessian</span><span class="op">)</span>,</span>
<span>        info <span class="op">=</span> <span class="op">-</span><span class="va">sol</span><span class="op">$</span><span class="va">hessian</span>,</span>
<span>        obs <span class="op">=</span> <span class="va">data</span>,</span>
<span>        nobs <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/length.html" class="external-link">length</a></span><span class="op">(</span><span class="va">data</span><span class="op">)</span>,</span>
<span>        superclasses <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html" class="external-link">c</a></span><span class="op">(</span><span class="st">"mle_weibull"</span><span class="op">)</span><span class="op">)</span></span>
<span><span class="op">}</span></span>
<span></span>
<span><span class="va">bias.mle_normal</span> <span class="op">&lt;-</span> <span class="kw">function</span><span class="op">(</span><span class="va">x</span>, <span class="va">theta</span> <span class="op">=</span> <span class="cn">NULL</span><span class="op">)</span> <span class="op">{</span></span>
<span>    <span class="kw">if</span> <span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/NULL.html" class="external-link">is.null</a></span><span class="op">(</span><span class="va">theta</span><span class="op">)</span><span class="op">)</span></span>
<span>        <span class="va">theta</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://queelius.github.io/algebraic.dist/reference/params.html" class="external-link">params</a></span><span class="op">(</span><span class="va">x</span><span class="op">)</span></span>
<span>    <span class="fu"><a href="https://rdrr.io/r/base/c.html" class="external-link">c</a></span><span class="op">(</span><span class="fl">0</span>, <span class="op">-</span><span class="va">theta</span><span class="op">[</span><span class="fl">2</span><span class="op">]</span> <span class="op">/</span> <span class="fu"><a href="https://rdrr.io/r/stats/nobs.html" class="external-link">nobs</a></span><span class="op">(</span><span class="va">x</span><span class="op">)</span><span class="op">)</span></span>
<span><span class="op">}</span></span>
<span></span>
<span><span class="va">theta.hat</span> <span class="op">&lt;-</span> <span class="fu">fit_normal</span><span class="op">(</span><span class="va">x</span><span class="op">)</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/base/summary.html" class="external-link">summary</a></span><span class="op">(</span><span class="va">theta.hat</span><span class="op">)</span></span>
<span><span class="co">#&gt; Maximum likelihood estimator of type mle_normal is normally distributed.</span></span>
<span><span class="co">#&gt; The estimates of the parameters are given by:</span></span>
<span><span class="co">#&gt; [1]  8.23 19.11</span></span>
<span><span class="co">#&gt; The standard error is  0.437 2.7 .</span></span>
<span><span class="co">#&gt; The asymptotic 95% confidence interval of the parameters are given by:</span></span>
<span><span class="co">#&gt;         2.5% 97.5%</span></span>
<span><span class="co">#&gt; param1  7.37  9.09</span></span>
<span><span class="co">#&gt; param2 13.82 24.41</span></span>
<span><span class="co">#&gt; The MSE of the individual components in a multivariate estimator is:</span></span>
<span><span class="co">#&gt;                  [,1]             [,2]</span></span>
<span><span class="co">#&gt; [1,] 0.19112701130551 0.00000000000607</span></span>
<span><span class="co">#&gt; [2,] 0.00000000000607 7.34243642454061</span></span>
<span><span class="co">#&gt; The log-likelihood is  -289 .</span></span>
<span><span class="co">#&gt; The AIC is  583 .</span></span>
<span></span>
<span><span class="va">theta.weibull</span> <span class="op">&lt;-</span> <span class="fu">fit_weibull</span><span class="op">(</span><span class="va">x</span><span class="op">)</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/base/summary.html" class="external-link">summary</a></span><span class="op">(</span><span class="va">theta.weibull</span><span class="op">)</span></span>
<span><span class="co">#&gt; Maximum likelihood estimator of type mle_weibull is normally distributed.</span></span>
<span><span class="co">#&gt; The estimates of the parameters are given by:</span></span>
<span><span class="co">#&gt; [1] 1.95 9.27</span></span>
<span><span class="co">#&gt; The standard error is  0.153 0.5 .</span></span>
<span><span class="co">#&gt; The asymptotic 95% confidence interval of the parameters are given by:</span></span>
<span><span class="co">#&gt;        2.5% 97.5%</span></span>
<span><span class="co">#&gt; param1 1.65  2.25</span></span>
<span><span class="co">#&gt; param2 8.29 10.25</span></span>
<span><span class="co">#&gt; The MSE of the individual components in a multivariate estimator is:</span></span>
<span><span class="co">#&gt;        [,1]   [,2]</span></span>
<span><span class="co">#&gt; [1,] 0.0235 0.0237</span></span>
<span><span class="co">#&gt; [2,] 0.0237 0.2497</span></span>
<span><span class="co">#&gt; The log-likelihood is  -284 .</span></span>
<span><span class="co">#&gt; The AIC is  573 .</span></span></code></pre></div>
<p>Let‚Äôs plot the pdfs of the Weibull and normal distributions:
<img src="fitting-common-dist_files/figure-html/unnamed-chunk-5-1.png" class="r-plt" width="384" style="display: block; margin: auto;"></p>
<p>In purple, we have the true density (DGP). In red, we have the
Weibull density. In green, we have the normal density. From the plot,
it‚Äôs hard to tell which distribution is a better fit to the DGP.</p>
<p>Interestingly, the tails of the true distribution seem a bit heavier
than the tails of the Weibull and Normal. This may suggest that a
heavier-tailed model may be a better fit, such as the lognormal
distribution, but we will not pursue this.</p>
<div class="section level3">
<h3 id="performance-measures-of-the-mle">Performance Measures of the MLE<a class="anchor" aria-label="anchor" href="#performance-measures-of-the-mle"></a>
</h3>
<p>A nice property of MLEs is that, asymptotically, given some
regularity conditions, they are normally distributed with a mean given
by the true true parameter and a variance-covariance given by the
inverse of the FIM evaluated at
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>Œ∏</mi><annotation encoding="application/x-tex">\theta</annotation></semantics></math>.</p>
<p>We do not know
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>Œ∏</mi><annotation encoding="application/x-tex">\theta</annotation></semantics></math>,
but we have have estimates, and thus we may approximate the sampling
distribution of
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mover><mi>Œ∏</mi><mo accent="true">ÃÇ</mo></mover><annotation encoding="application/x-tex">\hat\theta</annotation></semantics></math>
with
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>ùí©</mi><mrow><mo stretchy="true" form="prefix">(</mo><mover><mi>Œ∏</mi><mo accent="true">ÃÇ</mo></mover><mo>,</mo><msup><mi>I</mi><mrow><mo>‚àí</mo><mn>1</mn></mrow></msup><mrow><mo stretchy="true" form="prefix">(</mo><mover><mi>Œ∏</mi><mo accent="true">ÃÇ</mo></mover><mo stretchy="true" form="postfix">)</mo></mrow><mo stretchy="true" form="postfix">)</mo></mrow></mrow><annotation encoding="application/x-tex">\mathcal{N}(\hat\theta,I^{-1}(\hat\theta))</annotation></semantics></math>.</p>
<p>Let
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>F</mi><annotation encoding="application/x-tex">F</annotation></semantics></math>
denote the true distribution function such that
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>X</mi><mi>j</mi></msub><mo>‚àº</mo><mi>F</mi></mrow><annotation encoding="application/x-tex">X_j \sim F</annotation></semantics></math>
for all
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>j</mi><annotation encoding="application/x-tex">j</annotation></semantics></math>.
Suppose we have some population parameter
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>Œ∏</mi><mo>=</mo><mi>t</mi><mrow><mo stretchy="true" form="prefix">(</mo><mi>F</mi><mo stretchy="true" form="postfix">)</mo></mrow></mrow><annotation encoding="application/x-tex">\theta = t(F)</annotation></semantics></math>
and an estimator of
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>Œ∏</mi><annotation encoding="application/x-tex">\theta</annotation></semantics></math>
given by
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mover><mi>Œ∏</mi><mo accent="true">ÃÇ</mo></mover><mo>=</mo><mi>s</mi><mrow><mo stretchy="true" form="prefix">(</mo><mo stretchy="false" form="prefix">{</mo><msub><mi>X</mi><mn>1</mn></msub><mo>,</mo><mi>‚Ä¶</mi><mo>,</mo><msub><mi>X</mi><mi>n</mi></msub><mo stretchy="false" form="postfix">}</mo><mo stretchy="true" form="postfix">)</mo></mrow></mrow><annotation encoding="application/x-tex">\hat\theta = s(\{X_1,\ldots,X_n\})</annotation></semantics></math>.
A reasonable requirement for an estimator
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mover><mi>Œ∏</mi><mo accent="true">ÃÇ</mo></mover><annotation encoding="application/x-tex">\hat\theta</annotation></semantics></math>
is that it converges to the true parameter value
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>Œ∏</mi><annotation encoding="application/x-tex">\theta</annotation></semantics></math>
as we collect more and more data. In particular, we say that it is a
consistent estimator of
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>Œ∏</mi><annotation encoding="application/x-tex">\theta</annotation></semantics></math>
if
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mover><mi>Œ∏</mi><mo accent="true">ÃÇ</mo></mover><annotation encoding="application/x-tex">\hat\theta</annotation></semantics></math>
converges in probability to
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>Œ∏</mi><annotation encoding="application/x-tex">\theta</annotation></semantics></math>,
denoted by
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mover><mi>Œ∏</mi><mo accent="true">ÃÇ</mo></mover><mover><mo>‚Ü¶</mo><mi>p</mi></mover><mi>Œ∏</mi></mrow><annotation encoding="application/x-tex">\hat\theta \overset{p}{\mapsto} \theta</annotation></semantics></math>.</p>
<p>If the regularity conditions hold for the MLE, then
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mover><mi>Œ∏</mi><mo accent="true">ÃÇ</mo></mover><annotation encoding="application/x-tex">\hat\theta</annotation></semantics></math>
is a consistent estimator of
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>Œ∏</mi><annotation encoding="application/x-tex">\theta</annotation></semantics></math>.
However, for finite sample sizes, the estimator may be biased. The bias
of
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mover><mi>Œ∏</mi><mo accent="true">ÃÇ</mo></mover><annotation encoding="application/x-tex">\hat\theta</annotation></semantics></math>
with respect to
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>Œ∏</mi><annotation encoding="application/x-tex">\theta</annotation></semantics></math>
is defined as
<math display="block" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mo>bias</mo><mrow><mo stretchy="true" form="prefix">(</mo><mover><mi>Œ∏</mi><mo accent="true">ÃÇ</mo></mover><mo>,</mo><mi>Œ∏</mi><mo stretchy="true" form="postfix">)</mo></mrow><mo>=</mo><mi>E</mi><mrow><mo stretchy="true" form="prefix">(</mo><mover><mi>Œ∏</mi><mo accent="true">ÃÇ</mo></mover><mo stretchy="true" form="postfix">)</mo></mrow><mo>‚àí</mo><mi>Œ∏</mi><mo>,</mo></mrow><annotation encoding="application/x-tex">
    \operatorname{bias}(\hat\theta,\theta) = E(\hat\theta) - \theta,
</annotation></semantics></math> where
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mo>bias</mo><mrow><mo stretchy="true" form="prefix">(</mo><mover><mi>Œ∏</mi><mo accent="true">ÃÇ</mo></mover><mo>,</mo><mi>Œ∏</mi><mo stretchy="true" form="postfix">)</mo></mrow><mo>=</mo><mn>0</mn></mrow><annotation encoding="application/x-tex">\operatorname{bias}(\hat\theta,\theta) = 0</annotation></semantics></math>
indicates that
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mover><mi>Œ∏</mi><mo accent="true">ÃÇ</mo></mover><annotation encoding="application/x-tex">\hat\theta</annotation></semantics></math>
is an <em>unbiased</em> estimator of
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>Œ∏</mi><annotation encoding="application/x-tex">\theta</annotation></semantics></math>.</p>
<p>As a function of the true distribution
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>F</mi><annotation encoding="application/x-tex">F</annotation></semantics></math>,
the bias is unknown and is not a statistic. However, in the case of the
normal,
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mover><mi>Œº</mi><mo accent="true">ÃÇ</mo></mover><annotation encoding="application/x-tex">\hat\mu</annotation></semantics></math>
is unbiased and, analytically, the bias of
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><msup><mover><mi>œÉ</mi><mo accent="true">ÃÇ</mo></mover><mn>2</mn></msup><annotation encoding="application/x-tex">\hat\sigma^2</annotation></semantics></math>
is given by
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mo>‚àí</mo><mfrac><mn>1</mn><mi>n</mi></mfrac><msup><mi>œÉ</mi><mn>2</mn></msup></mrow><annotation encoding="application/x-tex">-\frac{1}{n} \sigma^2</annotation></semantics></math>:</p>
<div class="sourceCode" id="cb6"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu"><a href="../reference/bias.html">bias</a></span><span class="op">(</span><span class="va">theta.hat</span>,<span class="va">theta</span><span class="op">)</span></span>
<span><span class="co">#&gt; [1]  0.0 -0.1</span></span></code></pre></div>
<p>If
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><msup><mi>œÉ</mi><mn>2</mn></msup><annotation encoding="application/x-tex">\sigma^2</annotation></semantics></math>
is not known, we may estimate it by using replacing
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><msup><mover><mi>œÉ</mi><mo accent="true">ÃÇ</mo></mover><mn>2</mn></msup><annotation encoding="application/x-tex">\hat\sigma^2</annotation></semantics></math>
instead:</p>
<div class="sourceCode" id="cb7"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu"><a href="../reference/bias.html">bias</a></span><span class="op">(</span><span class="va">theta.hat</span><span class="op">)</span></span>
<span><span class="co">#&gt; [1]  0.000 -0.191</span></span></code></pre></div>
<p>This is pretty far off from the true bias. This may be the first
indication that the DGP is far from being normal.</p>
<p>If we wanted to estimate the bias for the Weibull, we could bootstrap
it or something else, but we don‚Äôt attempt to do that here.</p>
<p>The mean squared error (MSE) is another performance measure of an
estimator. It is given by
<math display="block" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mo>mse</mo><mrow><mo stretchy="true" form="prefix">(</mo><mover><mi>Œ∏</mi><mo accent="true">ÃÇ</mo></mover><mo stretchy="true" form="postfix">)</mo></mrow><mo>=</mo><mi>E</mi><mo minsize="1.2" maxsize="1.2" stretchy="false" form="prefix">{</mo><msup><mrow><mo stretchy="true" form="prefix">(</mo><mover><mi>Œ∏</mi><mo accent="true">ÃÇ</mo></mover><mo>‚àí</mo><mi>Œ∏</mi><mo stretchy="true" form="postfix">)</mo></mrow><mi>T</mi></msup><mrow><mo stretchy="true" form="prefix">(</mo><mover><mi>Œ∏</mi><mo accent="true">ÃÇ</mo></mover><mo>‚àí</mo><mi>Œ∏</mi><mo stretchy="true" form="postfix">)</mo></mrow><mo minsize="1.2" maxsize="1.2" stretchy="false" form="postfix">}</mo><mo>,</mo></mrow><annotation encoding="application/x-tex">
    \operatorname{mse}(\hat\theta) = E\bigl\{(\hat\theta - \theta)^T(\hat\theta - \theta)\bigr\},
</annotation></semantics></math> Another way to compute the MSE is given
by
<math display="block" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mo>mse</mo><mrow><mo stretchy="true" form="prefix">(</mo><mover><mi>Œ∏</mi><mo accent="true">ÃÇ</mo></mover><mo stretchy="true" form="postfix">)</mo></mrow><mo>=</mo><mo>trace</mo><mo stretchy="false" form="prefix">(</mo><mo>cov</mo><mrow><mo stretchy="true" form="prefix">(</mo><mover><mi>Œ∏</mi><mo accent="true">ÃÇ</mo></mover><mo stretchy="true" form="postfix">)</mo></mrow><mo>+</mo><mo>bias</mo><msup><mrow><mo stretchy="true" form="prefix">(</mo><mover><mi>Œ∏</mi><mo accent="true">ÃÇ</mo></mover><mo stretchy="true" form="postfix">)</mo></mrow><mi>T</mi></msup><mo>bias</mo><mrow><mo stretchy="true" form="prefix">(</mo><mover><mi>Œ∏</mi><mo accent="true">ÃÇ</mo></mover><mo stretchy="true" form="postfix">)</mo></mrow><mi>.</mi></mrow><annotation encoding="application/x-tex">
    \operatorname{mse}(\hat\theta) =
        \operatorname{trace}(\operatorname{cov}(\hat\theta) +
        \operatorname{bias}(\hat\theta)^T
        \operatorname{bias}(\hat\theta).
</annotation></semantics></math></p>
<p>Here‚Äôs R code to compute the MSE of
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mover><mi>Œ∏</mi><mo accent="true">ÃÇ</mo></mover><annotation encoding="application/x-tex">\hat\theta</annotation></semantics></math>:</p>
<div class="sourceCode" id="cb8"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu"><a href="https://rdrr.io/r/base/Round.html" class="external-link">round</a></span><span class="op">(</span><span class="fu"><a href="../reference/mse.html">mse</a></span><span class="op">(</span><span class="va">theta.hat</span><span class="op">)</span>, digits<span class="op">=</span><span class="fl">3</span><span class="op">)</span></span>
<span><span class="co">#&gt;       [,1] [,2]</span></span>
<span><span class="co">#&gt; [1,] 0.191 0.00</span></span>
<span><span class="co">#&gt; [2,] 0.000 7.34</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/base/Round.html" class="external-link">round</a></span><span class="op">(</span><span class="fu"><a href="../reference/mse.html">mse</a></span><span class="op">(</span><span class="va">theta.weibull</span><span class="op">)</span>, digits<span class="op">=</span><span class="fl">3</span><span class="op">)</span>  <span class="co"># true MSE</span></span>
<span><span class="co">#&gt;       [,1]  [,2]</span></span>
<span><span class="co">#&gt; [1,] 0.023 0.024</span></span>
<span><span class="co">#&gt; [2,] 0.024 0.250</span></span></code></pre></div>
<p>The normal distribution has significant MSE compared to the
Weibull.</p>
</div>
</div>
<div class="section level2">
<h2 id="invariance-property-of-the-mle">Invariance Property of the MLE<a class="anchor" aria-label="anchor" href="#invariance-property-of-the-mle"></a>
</h2>
<p>An interesting property of an MLE
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mover><mi>Œ∏</mi><mo accent="true">ÃÇ</mo></mover><annotation encoding="application/x-tex">\hat\theta</annotation></semantics></math>
is that the MLE of
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>f</mi><mrow><mo stretchy="true" form="prefix">(</mo><mi>Œ∏</mi><mo stretchy="true" form="postfix">)</mo></mrow></mrow><annotation encoding="application/x-tex">f(\theta)</annotation></semantics></math>
is given by
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>f</mi><mrow><mo stretchy="true" form="prefix">(</mo><mover><mi>Œ∏</mi><mo accent="true">ÃÇ</mo></mover><mo stretchy="true" form="postfix">)</mo></mrow></mrow><annotation encoding="application/x-tex">f(\hat\theta)</annotation></semantics></math>.
What is the distribution of
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>f</mi><mrow><mo stretchy="true" form="prefix">(</mo><mover><mi>Œ∏</mi><mo accent="true">ÃÇ</mo></mover><mo stretchy="true" form="postfix">)</mo></mrow></mrow><annotation encoding="application/x-tex">f(\hat\theta)</annotation></semantics></math>?
Asymptotically, it is normally distributed with a mean given by
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>f</mi><mrow><mo stretchy="true" form="prefix">(</mo><mi>Œ∏</mi><mo stretchy="true" form="postfix">)</mo></mrow></mrow><annotation encoding="application/x-tex">f(\theta)</annotation></semantics></math>
and a variace-covariance given by the covariance of the sampling
distribution of
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>f</mi><mrow><mo stretchy="true" form="prefix">(</mo><mover><mi>Œ∏</mi><mo accent="true">ÃÇ</mo></mover><mo stretchy="true" form="postfix">)</mo></mrow></mrow><annotation encoding="application/x-tex">f(\hat\theta)</annotation></semantics></math>.</p>
<p>We provide two methods to compute the variance-covariance.</p>
<div class="section level3">
<h3 id="delta-method">Delta Method<a class="anchor" aria-label="anchor" href="#delta-method"></a>
</h3>
<p>If
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>f</mi><annotation encoding="application/x-tex">f</annotation></semantics></math>
is differentiable, the variance-covariance is given by
<math display="block" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mo>var</mo><mrow><mo stretchy="true" form="prefix">(</mo><mi>f</mi><mrow><mo stretchy="true" form="prefix">(</mo><mover><mi>Œ∏</mi><mo accent="true">ÃÇ</mo></mover><mo stretchy="true" form="postfix">)</mo></mrow><mo stretchy="true" form="postfix">)</mo></mrow><mo>=</mo><mo>E</mo><mo minsize="1.2" maxsize="1.2" stretchy="false" form="prefix">{</mo><mo minsize="1.2" maxsize="1.2" stretchy="false" form="prefix">(</mo><mi>f</mi><mrow><mo stretchy="true" form="prefix">(</mo><mover><mi>Œ∏</mi><mo accent="true">ÃÇ</mo></mover><mo stretchy="true" form="postfix">)</mo></mrow><mo>‚àí</mo><mi>f</mi><mrow><mo stretchy="true" form="prefix">(</mo><mi>Œ∏</mi><mo stretchy="true" form="postfix">)</mo></mrow><msup><mo minsize="1.2" maxsize="1.2" stretchy="false" form="postfix">)</mo><mn>2</mn></msup><mo minsize="1.2" maxsize="1.2" stretchy="false" form="postfix">}</mo><mo>=</mo><mo>E</mo><mo minsize="1.2" maxsize="1.2" stretchy="false" form="prefix">{</mo><msub><mi>J</mi><mi>f</mi></msub><mrow><mo stretchy="true" form="prefix">(</mo><mover><mi>Œ∏</mi><mo accent="true">ÃÇ</mo></mover><mo stretchy="true" form="postfix">)</mo></mrow><mi>I</mi><msup><mrow><mo stretchy="true" form="prefix">(</mo><mover><mi>Œ∏</mi><mo accent="true">ÃÇ</mo></mover><mo stretchy="true" form="postfix">)</mo></mrow><mrow><mo>‚àí</mo><mn>1</mn></mrow></msup><msub><mi>J</mi><mi>f</mi></msub><msup><mrow><mo stretchy="true" form="prefix">(</mo><mover><mi>Œ∏</mi><mo accent="true">ÃÇ</mo></mover><mo stretchy="true" form="postfix">)</mo></mrow><mi>T</mi></msup><mo minsize="1.2" maxsize="1.2" stretchy="false" form="postfix">}</mo><mi>.</mi></mrow><annotation encoding="application/x-tex">
\operatorname{var}(f(\hat\theta)) = \operatorname{E}\bigl\{
    \bigl(f(\hat\theta) - f(\theta)\bigr)^2\bigr\} =
    \operatorname{E}\bigl\{J_f(\hat\theta) I(\hat\theta)^{-1} J_f(\hat\theta)^T\bigr\}.
</annotation></semantics></math> Here,
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>J</mi><mi>f</mi></msub><mrow><mo stretchy="true" form="prefix">(</mo><mover><mi>Œ∏</mi><mo accent="true">ÃÇ</mo></mover><mo stretchy="true" form="postfix">)</mo></mrow></mrow><annotation encoding="application/x-tex">J_f(\hat\theta)</annotation></semantics></math>
is the Jacobian of
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>f</mi><annotation encoding="application/x-tex">f</annotation></semantics></math>
evaluated at
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mover><mi>Œ∏</mi><mo accent="true">ÃÇ</mo></mover><annotation encoding="application/x-tex">\hat\theta</annotation></semantics></math>.</p>
</div>
<div class="section level3">
<h3 id="monte-carlo-method">Monte-Carlo Method<a class="anchor" aria-label="anchor" href="#monte-carlo-method"></a>
</h3>
<p>The delta method requires that
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>f</mi><annotation encoding="application/x-tex">f</annotation></semantics></math>
be differentiable, but we may use the Monte-carlo method to estimate the
distribution of
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>f</mi><mrow><mo stretchy="true" form="prefix">(</mo><mover><mi>Œ∏</mi><mo accent="true">ÃÇ</mo></mover><mo stretchy="true" form="postfix">)</mo></mrow></mrow><annotation encoding="application/x-tex">f(\hat\theta)</annotation></semantics></math>
for any function
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>f</mi><annotation encoding="application/x-tex">f</annotation></semantics></math>.
We simply sample from the MLE of
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mover><mi>Œ∏</mi><mo accent="true">ÃÇ</mo></mover><annotation encoding="application/x-tex">\hat\theta</annotation></semantics></math>
and apply
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>f</mi><annotation encoding="application/x-tex">f</annotation></semantics></math>
to its estimates and take the covariance of the sample.</p>
<p>Next, we show how to compute the sampling distribution of
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>g</mi><mrow><mo stretchy="true" form="prefix">(</mo><mover><mi>Œ∏</mi><mo accent="true">ÃÇ</mo></mover><mo stretchy="true" form="postfix">)</mo></mrow></mrow><annotation encoding="application/x-tex">g(\hat\theta)</annotation></semantics></math>
for some function
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>g</mi><annotation encoding="application/x-tex">g</annotation></semantics></math>
and some MLE
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mover><mi>Œ∏</mi><mo accent="true">ÃÇ</mo></mover><annotation encoding="application/x-tex">\hat\theta</annotation></semantics></math>
using both the delta and mc methods.</p>
</div>
<div class="section level3">
<h3 id="example-1">Example 1<a class="anchor" aria-label="anchor" href="#example-1"></a>
</h3>
<p>For this example, we use the Weibull fit. Let
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>g</mi><mrow><mo stretchy="true" form="prefix">(</mo><mi>Œ∏</mi><mo stretchy="true" form="postfix">)</mo></mrow><mo>=</mo><mi>A</mi><mi>Œ∏</mi><mo>+</mo><mi>b</mi></mrow><annotation encoding="application/x-tex">g(\theta) = A \theta + b</annotation></semantics></math>
for some matrix
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>A</mi><annotation encoding="application/x-tex">A</annotation></semantics></math>
and vector
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>b</mi><annotation encoding="application/x-tex">b</annotation></semantics></math>.
(This is a simple linear transformation of
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>Œ∏</mi><annotation encoding="application/x-tex">\theta</annotation></semantics></math>.)
We can define
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>g</mi><annotation encoding="application/x-tex">g</annotation></semantics></math>
in R with:</p>
<div class="sourceCode" id="cb9"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">A</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/matrix.html" class="external-link">matrix</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/c.html" class="external-link">c</a></span><span class="op">(</span><span class="fl">2</span>,<span class="fl">3</span><span class="op">)</span>,nrow<span class="op">=</span><span class="fl">2</span><span class="op">)</span></span>
<span><span class="va">b</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html" class="external-link">c</a></span><span class="op">(</span><span class="fl">1</span>,<span class="fl">0</span><span class="op">)</span></span>
<span><span class="va">g</span> <span class="op">&lt;-</span> <span class="kw">function</span><span class="op">(</span><span class="va">x</span><span class="op">)</span> <span class="va">A</span> <span class="op"><a href="https://rdrr.io/r/base/matmult.html" class="external-link">%*%</a></span> <span class="va">x</span> <span class="op">+</span> <span class="va">b</span></span></code></pre></div>
<p>We compute the variance-covariance of the MLE of
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>g</mi><mrow><mo stretchy="true" form="prefix">(</mo><mi>Œ∏</mi><mo stretchy="true" form="postfix">)</mo></mrow></mrow><annotation encoding="application/x-tex">g(\theta)</annotation></semantics></math>
using both methods:</p>
<div class="sourceCode" id="cb10"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">g.mc</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://queelius.github.io/algebraic.dist/reference/rmap.html" class="external-link">rmap</a></span><span class="op">(</span><span class="va">theta.weibull</span>,<span class="va">g</span>,n<span class="op">=</span><span class="fl">100000L</span><span class="op">)</span></span>
<span><span class="va">g.delta</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://queelius.github.io/algebraic.dist/reference/rmap.html" class="external-link">rmap</a></span><span class="op">(</span><span class="va">theta.weibull</span>,<span class="va">g</span>,method<span class="op">=</span><span class="st">"delta"</span><span class="op">)</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/base/Round.html" class="external-link">round</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/stats/vcov.html" class="external-link">vcov</a></span><span class="op">(</span><span class="va">g.mc</span><span class="op">)</span>, digits<span class="op">=</span><span class="fl">3</span><span class="op">)</span></span>
<span><span class="co">#&gt;       [,1]  [,2]  [,3]  [,4]</span></span>
<span><span class="co">#&gt; [1,] 0.095 0.142 0.095 0.143</span></span>
<span><span class="co">#&gt; [2,] 0.142 0.213 0.143 0.214</span></span>
<span><span class="co">#&gt; [3,] 0.095 0.143 1.003 1.504</span></span>
<span><span class="co">#&gt; [4,] 0.143 0.214 1.504 2.256</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/base/Round.html" class="external-link">round</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/stats/vcov.html" class="external-link">vcov</a></span><span class="op">(</span><span class="va">g.delta</span><span class="op">)</span>, digits<span class="op">=</span><span class="fl">3</span><span class="op">)</span></span>
<span><span class="co">#&gt;       [,1]  [,2]  [,3]  [,4]</span></span>
<span><span class="co">#&gt; [1,] 0.094 0.141 0.095 0.142</span></span>
<span><span class="co">#&gt; [2,] 0.141 0.211 0.142 0.213</span></span>
<span><span class="co">#&gt; [3,] 0.095 0.142 0.999 1.498</span></span>
<span><span class="co">#&gt; [4,] 0.142 0.213 1.498 2.247</span></span></code></pre></div>
<p>They are pretty close.</p>
</div>
</div>
<div class="section level2">
<h2 id="weighted-mle-a-weighted-sum-of-mles">Weighted MLE: A Weighted Sum of MLEs<a class="anchor" aria-label="anchor" href="#weighted-mle-a-weighted-sum-of-mles"></a>
</h2>
<p>Since the variance-covariance of an MLE is inversely proportional to
the Fisher information that the MLE is defined with respect to, we can
combine multiple MLEs of
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>Œ∏</mi><annotation encoding="application/x-tex">\theta</annotation></semantics></math>,
each of which may be defined with respect to a different kind of sample,
to arrive at the MLE that incorporates the Fisher information in all of
those samples.</p>
<p>Consider
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>k</mi><annotation encoding="application/x-tex">k</annotation></semantics></math>
mutually independent MLEs of parameter
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>Œ∏</mi><annotation encoding="application/x-tex">\theta</annotation></semantics></math>,
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mover><mi>Œ∏</mi><mo accent="true">ÃÇ</mo></mover><mn>1</mn></msub><mo>,</mo><mi>‚Ä¶</mi><mo>,</mo><msub><mover><mi>Œ∏</mi><mo accent="true">ÃÇ</mo></mover><mi>k</mi></msub></mrow><annotation encoding="application/x-tex">\hat\theta_1,\ldots,\hat\theta_k</annotation></semantics></math>,
where
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mover><mi>Œ∏</mi><mo accent="true">ÃÇ</mo></mover><mi>j</mi></msub><mo>‚àº</mo><mi>N</mi><mrow><mo stretchy="true" form="prefix">(</mo><mi>Œ∏</mi><mo>,</mo><msubsup><mi>I</mi><mi>j</mi><mrow><mo>‚àí</mo><mn>1</mn></mrow></msubsup><mrow><mo stretchy="true" form="prefix">(</mo><mi>Œ∏</mi><mo stretchy="true" form="postfix">)</mo></mrow><mo stretchy="true" form="postfix">)</mo></mrow></mrow><annotation encoding="application/x-tex">\hat\theta_j \sim N(\theta,I_j^{-1}(\theta))</annotation></semantics></math>.
Then, the sampling MLE of
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>Œ∏</mi><annotation encoding="application/x-tex">\theta</annotation></semantics></math>
that incorporates all of the data in
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mover><mi>Œ∏</mi><mo accent="true">ÃÇ</mo></mover><mn>1</mn></msub><mo>,</mo><mi>‚Ä¶</mi><mo>,</mo><msub><mover><mi>Œ∏</mi><mo accent="true">ÃÇ</mo></mover><mi>k</mi></msub></mrow><annotation encoding="application/x-tex">\hat\theta_1,\ldots,\hat\theta_k</annotation></semantics></math>
is given by the inverse-variance weighted mean,
<math display="block" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mover><mi>Œ∏</mi><mo accent="true">ÃÇ</mo></mover><mi>w</mi></msub><mo>=</mo><msup><mrow><mo stretchy="true" form="prefix">(</mo><munderover><mo>‚àë</mo><mrow><mi>j</mi><mo>=</mo><mn>1</mn></mrow><mi>k</mi></munderover><msub><mi>I</mi><mi>j</mi></msub><mrow><mo stretchy="true" form="prefix">(</mo><mi>Œ∏</mi><mo stretchy="true" form="postfix">)</mo></mrow><mo stretchy="true" form="postfix">)</mo></mrow><mrow><mo>‚àí</mo><mn>1</mn></mrow></msup><mrow><mo stretchy="true" form="prefix">(</mo><munderover><mo>‚àë</mo><mrow><mi>j</mi><mo>=</mo><mn>1</mn></mrow><mi>k</mi></munderover><msub><mi>I</mi><mi>j</mi></msub><mrow><mo stretchy="true" form="prefix">(</mo><mi>Œ∏</mi><mo stretchy="true" form="postfix">)</mo></mrow><msub><mover><mi>Œ∏</mi><mo accent="true">ÃÇ</mo></mover><mi>j</mi></msub><mo stretchy="true" form="postfix">)</mo></mrow><mo>,</mo></mrow><annotation encoding="application/x-tex">
    \hat\theta_w = \left(\sum_{j=1}^k I_j(\theta)\right)^{-1} \left(\sum_{j=1}^k I_j(\theta) \hat\theta_j\right),
</annotation></semantics></math> which, asymptotically, has an expected
value of
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>Œ∏</mi><annotation encoding="application/x-tex">\theta</annotation></semantics></math>
and a variance-covariance of
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><msup><mrow><mo stretchy="true" form="prefix">(</mo><msubsup><mo>‚àë</mo><mrow><mi>j</mi><mo>=</mo><mn>1</mn></mrow><mi>k</mi></msubsup><msub><mi>I</mi><mi>j</mi></msub><mrow><mo stretchy="true" form="prefix">(</mo><mi>Œ∏</mi><mo stretchy="true" form="postfix">)</mo></mrow><mo stretchy="true" form="postfix">)</mo></mrow><mrow><mo>‚àí</mo><mn>1</mn></mrow></msup><annotation encoding="application/x-tex">\left(\sum_{j=1}^k I_j(\theta)\right)^{-1}</annotation></semantics></math>.</p>
<div class="section level3">
<h3 id="example-2">Example 2<a class="anchor" aria-label="anchor" href="#example-2"></a>
</h3>
<p>For this example, we use the normal fit.</p>
<p>To evaluate the performance of the weighted MLE, we generate a sample
of
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>N</mi><mo>=</mo><mn>1000</mn></mrow><annotation encoding="application/x-tex">N=1000</annotation></semantics></math>
observations from
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>ùí©</mi><mrow><mo stretchy="true" form="prefix">(</mo><mi>Œ∏</mi><mo stretchy="true" form="postfix">)</mo></mrow></mrow><annotation encoding="application/x-tex">\mathcal{N}(\theta)</annotation></semantics></math>
and compute the MLE for the observed sample, denoted by
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mover><mi>Œ∏</mi><mo accent="true">ÃÇ</mo></mover><annotation encoding="application/x-tex">\hat\theta</annotation></semantics></math>.</p>
<p>We then divide the observed sample into
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>r</mi><mo>=</mo><mn>5</mn></mrow><annotation encoding="application/x-tex">r=5</annotation></semantics></math>
sub-samples, each of size
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>N</mi><mi>/</mi><mi>r</mi><mo>=</mo><mn>100</mn></mrow><annotation encoding="application/x-tex">N/r=100</annotation></semantics></math>,
and compute the MLE for each sub-sampled, denoted by
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msup><mi>Œ∏</mi><mrow><mo stretchy="true" form="prefix">(</mo><mn>1</mn><mo stretchy="true" form="postfix">)</mo></mrow></msup><mo>,</mo><mi>‚Ä¶</mi><mo>,</mo><msup><mi>Œ∏</mi><mrow><mo stretchy="true" form="prefix">(</mo><mi>r</mi><mo stretchy="true" form="postfix">)</mo></mrow></msup></mrow><annotation encoding="application/x-tex">\theta^{(1)},\ldots,\theta^{(r)}</annotation></semantics></math>.</p>
<p>Finally, we do a weighted combination these MLEs to form the weighted
MLE, denoted by
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><msub><mi>Œ∏</mi><mi>w</mi></msub><annotation encoding="application/x-tex">\theta_w</annotation></semantics></math>:</p>
<div class="sourceCode" id="cb11"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">N</span> <span class="op">&lt;-</span> <span class="fl">500</span></span>
<span><span class="va">r</span> <span class="op">&lt;-</span> <span class="fl">5</span></span>
<span><span class="va">samp</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/stats/Normal.html" class="external-link">rnorm</a></span><span class="op">(</span><span class="va">N</span>, mean <span class="op">=</span> <span class="va">theta</span><span class="op">[</span><span class="fl">1</span><span class="op">]</span>, sd <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/MathFun.html" class="external-link">sqrt</a></span><span class="op">(</span><span class="va">theta</span><span class="op">[</span><span class="fl">2</span><span class="op">]</span><span class="op">)</span><span class="op">)</span></span>
<span><span class="va">samp.sub</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/matrix.html" class="external-link">matrix</a></span><span class="op">(</span><span class="va">samp</span>, nrow <span class="op">=</span> <span class="va">r</span><span class="op">)</span></span>
<span><span class="va">mles.sub</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/list.html" class="external-link">list</a></span><span class="op">(</span>length <span class="op">=</span> <span class="va">r</span><span class="op">)</span></span>
<span><span class="kw">for</span> <span class="op">(</span><span class="va">i</span> <span class="kw">in</span> <span class="fl">1</span><span class="op">:</span><span class="va">r</span><span class="op">)</span></span>
<span>    <span class="va">mles.sub</span><span class="op">[[</span><span class="va">i</span><span class="op">]</span><span class="op">]</span> <span class="op">&lt;-</span> <span class="fu">fit_normal</span><span class="op">(</span><span class="va">samp.sub</span><span class="op">[</span><span class="va">i</span>,<span class="op">]</span><span class="op">)</span></span>
<span></span>
<span><span class="va">mle.wt</span> <span class="op">&lt;-</span> <span class="fu"><a href="../reference/mle_weighted.html">mle_weighted</a></span><span class="op">(</span><span class="va">mles.sub</span><span class="op">)</span></span>
<span><span class="va">mle</span> <span class="op">&lt;-</span> <span class="fu">fit_normal</span><span class="op">(</span><span class="va">samp</span><span class="op">)</span></span></code></pre></div>
<p>We show the results in the following R code. First, we show the
weighted MLE and its MSE:</p>
<div class="sourceCode" id="cb12"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu"><a href="https://queelius.github.io/algebraic.dist/reference/params.html" class="external-link">params</a></span><span class="op">(</span><span class="va">mle.wt</span><span class="op">)</span></span>
<span><span class="co">#&gt; [1] 1.98 8.71</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/base/Round.html" class="external-link">round</a></span><span class="op">(</span><span class="fu"><a href="../reference/mse.html">mse</a></span><span class="op">(</span><span class="va">mle.wt</span><span class="op">)</span>, digits<span class="op">=</span><span class="fl">3</span><span class="op">)</span></span>
<span><span class="co">#&gt;       [,1]  [,2]</span></span>
<span><span class="co">#&gt; [1,] 0.018 0.000</span></span>
<span><span class="co">#&gt; [2,] 0.000 0.313</span></span></code></pre></div>
<p>The MLE for the total sample and its MSE is:</p>
<div class="sourceCode" id="cb13"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu"><a href="https://queelius.github.io/algebraic.dist/reference/params.html" class="external-link">params</a></span><span class="op">(</span><span class="va">mle</span><span class="op">)</span></span>
<span><span class="co">#&gt; [1] 1.98 9.28</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/base/Round.html" class="external-link">round</a></span><span class="op">(</span><span class="fu"><a href="../reference/mse.html">mse</a></span><span class="op">(</span><span class="va">mle</span><span class="op">)</span>, digits<span class="op">=</span><span class="fl">3</span><span class="op">)</span></span>
<span><span class="co">#&gt;       [,1]  [,2]</span></span>
<span><span class="co">#&gt; [1,] 0.019 0.000</span></span>
<span><span class="co">#&gt; [2,] 0.000 0.345</span></span></code></pre></div>
<p>We see that
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mover><mi>Œ∏</mi><mo accent="true">ÃÇ</mo></mover><annotation encoding="application/x-tex">\hat\theta</annotation></semantics></math>
and
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><msub><mover><mi>Œ∏</mi><mo accent="true">ÃÇ</mo></mover><mi>w</mi></msub><annotation encoding="application/x-tex">\hat\theta_w</annotation></semantics></math>
model approximately the same sampling distribution.</p>
</div>
</div>
<div class="section level2">
<h2 id="bootstrapping-the-mles">Bootstrapping the MLEs<a class="anchor" aria-label="anchor" href="#bootstrapping-the-mles"></a>
</h2>
<p>Let‚Äôs compare the earlier results that relied on the large sampling
assumption with the bootstrapped MLE using <code>mle_boot</code>. First,
<code>mle_boot</code> is just a wrapper for <code>boot</code> objects or
objects like <code>boot</code>. Thus to use <code>mle_boot</code>, we
first need to call <code>boot</code> to bootstrap our MLE for the
Weibull fit.</p>
<p>We just need to wrap it in a function that takes the data as input
and returns the MLE of the parameters and then pass it to
<code>mle_boot</code> constructor:</p>
<div class="sourceCode" id="cb14"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">theta.boot</span> <span class="op">&lt;-</span> <span class="fu"><a href="../reference/mle_boot.html">mle_boot</a></span><span class="op">(</span></span>
<span>    <span class="fu"><a href="https://rdrr.io/pkg/boot/man/boot.html" class="external-link">boot</a></span><span class="op">(</span>data <span class="op">=</span> <span class="va">x</span>,</span>
<span>         statistic <span class="op">=</span> <span class="kw">function</span><span class="op">(</span><span class="va">x</span>, <span class="va">i</span><span class="op">)</span> <span class="fu"><a href="https://queelius.github.io/algebraic.dist/reference/params.html" class="external-link">params</a></span><span class="op">(</span><span class="fu">fit_weibull</span><span class="op">(</span><span class="va">x</span><span class="op">[</span><span class="va">i</span><span class="op">]</span><span class="op">)</span><span class="op">)</span>,</span>
<span>         R <span class="op">=</span> <span class="fl">1000</span><span class="op">)</span><span class="op">)</span></span></code></pre></div>
<p>We already printed out the <code>theta.boot</code> object, which
provided a lot of information about it, but we can obtain specified
statistics from the Bootstrap MLE using the standard interface in
<code>algorithmic.mle</code>, e.g.:</p>
<div class="sourceCode" id="cb15"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu"><a href="https://rdrr.io/r/base/print.html" class="external-link">print</a></span><span class="op">(</span><span class="va">theta.boot</span><span class="op">)</span></span>
<span><span class="co">#&gt; Maximum likelihood estimator of type mle_boot is normally distributed.</span></span>
<span><span class="co">#&gt; The estimates of the parameters are given by:</span></span>
<span><span class="co">#&gt; [1] 1.95 9.27</span></span>
<span><span class="co">#&gt; The standard error is  0.153 0.501 .</span></span>
<span><span class="co">#&gt; The asymptotic 95% confidence interval of the parameters are given by:</span></span>
<span><span class="co">#&gt;        2.5% 97.5%</span></span>
<span><span class="co">#&gt; param1 1.64  2.23</span></span>
<span><span class="co">#&gt; param2 8.31 10.28</span></span>
<span><span class="co">#&gt; The MSE of the individual components in a multivariate estimator is:</span></span>
<span><span class="co">#&gt;        [,1]   [,2]</span></span>
<span><span class="co">#&gt; [1,] 0.0235 0.0283</span></span>
<span><span class="co">#&gt; [2,] 0.0283 0.2519</span></span>
<span><span class="fu"><a href="../reference/bias.html">bias</a></span><span class="op">(</span><span class="va">theta.boot</span><span class="op">)</span></span>
<span><span class="co">#&gt; [1]  0.0159 -0.0228</span></span></code></pre></div>
<p>We see that, for the most part, the results are similar to those
obtained using the large sampling assumption.</p>
</div>
<div class="section level2">
<h2 id="goodness-of-fit">Goodness-of-Fit<a class="anchor" aria-label="anchor" href="#goodness-of-fit"></a>
</h2>
<p>We are fitting a model to the data that does not precisely capture
the generative model
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>W</mi><annotation encoding="application/x-tex">W</annotation></semantics></math>.
So, how good of a fit is it?</p>
<p>We will conduct a goodness of fit test,
<math display="block" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mtable><mtr><mtd columnalign="right" style="text-align: right"><msub><mi>H</mi><mn>0</mn></msub></mtd><mtd columnalign="left" style="text-align: left"><mo>:</mo><mtext mathvariant="normal">the data is compatible with the Weibull distribution</mtext></mtd></mtr><mtr><mtd columnalign="right" style="text-align: right"><msub><mi>H</mi><mi>A</mi></msub></mtd><mtd columnalign="left" style="text-align: left"><mo>:</mo><mtext mathvariant="normal">the data is not compatible with the Weibull distribution</mtext><mi>.</mi></mtd></mtr></mtable><annotation encoding="application/x-tex">\begin{align}
  H_0 &amp;: \text{the data is compatible with the Weibull distribution}\\
  H_A &amp;: \text{the data is not compatible with the Weibull distribution}.
\end{align}</annotation></semantics></math></p>
<p>To perform this test, we will use the Cramer-von Mises test. This
test is based on the Cramer-von Mises statistic, which is a measure of
the distance between the empirical distribution function of the data and
the distribution function of the model. The Cramer-von Mises statistic
is given by
<math display="block" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msubsup><mover><mi>D</mi><mo accent="true">ÃÇ</mo></mover><mi>n</mi><mn>2</mn></msubsup><mo>=</mo><mfrac><mn>1</mn><mi>n</mi></mfrac><munderover><mo>‚àë</mo><mrow><mi>i</mi><mo>=</mo><mn>1</mn></mrow><mi>n</mi></munderover><msup><mrow><mo stretchy="true" form="prefix">(</mo><msub><mover><mi>F</mi><mo accent="true">ÃÇ</mo></mover><mi>n</mi></msub><mrow><mo stretchy="true" form="prefix">(</mo><msub><mi>x</mi><mi>i</mi></msub><mo stretchy="true" form="postfix">)</mo></mrow><mo>‚àí</mo><mi>F</mi><mrow><mo stretchy="true" form="prefix">(</mo><msub><mi>x</mi><mi>i</mi></msub><mo stretchy="true" form="postfix">)</mo></mrow><mo stretchy="true" form="postfix">)</mo></mrow><mn>2</mn></msup></mrow><annotation encoding="application/x-tex">
  \hat D_n^2 = \frac{1}{n}\sum_{i=1}^n \left(\hat F_n(x_i) - F(x_i)\right)^2
</annotation></semantics></math> where
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><msub><mover><mi>F</mi><mo accent="true">ÃÇ</mo></mover><mi>n</mi></msub><annotation encoding="application/x-tex">\hat F_n</annotation></semantics></math>
is the empirical distribution function of the data and
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>F</mi><annotation encoding="application/x-tex">F</annotation></semantics></math>
is the distribution function of the model.</p>
<div class="sourceCode" id="cb16"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">cramer.test</span> <span class="op">&lt;-</span> <span class="kw">function</span><span class="op">(</span><span class="va">obs.dat</span>,<span class="va">ref.dat</span><span class="op">)</span></span>
<span><span class="op">{</span></span>
<span>  <span class="va">stat</span> <span class="op">&lt;-</span> <span class="fu">CDFt</span><span class="fu">::</span><span class="fu"><a href="https://rdrr.io/pkg/CDFt/man/CramerVonMisesTwoSamples.html" class="external-link">CramerVonMisesTwoSamples</a></span><span class="op">(</span><span class="va">obs.dat</span>,<span class="va">ref.dat</span><span class="op">)</span></span>
<span>  <span class="fu"><a href="https://rdrr.io/r/base/list.html" class="external-link">list</a></span><span class="op">(</span>p.value<span class="op">=</span><span class="fu"><a href="https://rdrr.io/r/base/Log.html" class="external-link">exp</a></span><span class="op">(</span><span class="op">-</span><span class="va">stat</span><span class="op">)</span><span class="op">/</span><span class="fl">6.0</span>,</span>
<span>       cramer.stat<span class="op">=</span><span class="va">stat</span>,</span>
<span>       obs.size<span class="op">=</span><span class="fu"><a href="https://rdrr.io/r/base/length.html" class="external-link">length</a></span><span class="op">(</span><span class="va">obs.dat</span><span class="op">)</span>,</span>
<span>       ref.size<span class="op">=</span><span class="fu"><a href="https://rdrr.io/r/base/length.html" class="external-link">length</a></span><span class="op">(</span><span class="va">ref.dat</span><span class="op">)</span><span class="op">)</span></span>
<span><span class="op">}</span></span>
<span></span>
<span><span class="va">wei.shape</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://queelius.github.io/algebraic.dist/reference/params.html" class="external-link">params</a></span><span class="op">(</span><span class="va">theta.weibull</span><span class="op">)</span><span class="op">[</span><span class="fl">1</span><span class="op">]</span></span>
<span><span class="va">wei.scale</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://queelius.github.io/algebraic.dist/reference/params.html" class="external-link">params</a></span><span class="op">(</span><span class="va">theta.weibull</span><span class="op">)</span><span class="op">[</span><span class="fl">2</span><span class="op">]</span></span>
<span><span class="va">ref.dat</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/stats/Weibull.html" class="external-link">rweibull</a></span><span class="op">(</span><span class="fl">1000000</span>, shape <span class="op">=</span> <span class="va">wei.shape</span>, scale <span class="op">=</span> <span class="va">wei.scale</span><span class="op">)</span></span>
<span><span class="fu">cramer.test</span><span class="op">(</span><span class="va">x</span>, <span class="va">ref.dat</span><span class="op">)</span></span>
<span><span class="co">#&gt; $p.value</span></span>
<span><span class="co">#&gt; [1] 0.16</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; $cramer.stat</span></span>
<span><span class="co">#&gt; [1] 0.042</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; $obs.size</span></span>
<span><span class="co">#&gt; [1] 100</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; $ref.size</span></span>
<span><span class="co">#&gt; [1] 1000000</span></span></code></pre></div>
<p>Looking at the
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>p</mi><annotation encoding="application/x-tex">p</annotation></semantics></math>-value,
we see that the data is compatible with the Weibull distribution. Now,
let‚Äôs do the same for the normal distribution:</p>
<div class="sourceCode" id="cb17"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">norm.mu</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://queelius.github.io/algebraic.dist/reference/params.html" class="external-link">params</a></span><span class="op">(</span><span class="va">theta.hat</span><span class="op">)</span><span class="op">[</span><span class="fl">1</span><span class="op">]</span></span>
<span><span class="va">norm.var</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://queelius.github.io/algebraic.dist/reference/params.html" class="external-link">params</a></span><span class="op">(</span><span class="va">theta.hat</span><span class="op">)</span><span class="op">[</span><span class="fl">2</span><span class="op">]</span></span>
<span><span class="va">ref.dat</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/stats/Normal.html" class="external-link">rnorm</a></span><span class="op">(</span><span class="fl">1000000</span>, mean <span class="op">=</span> <span class="va">norm.mu</span>, sd <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/MathFun.html" class="external-link">sqrt</a></span><span class="op">(</span><span class="va">norm.var</span><span class="op">)</span><span class="op">)</span></span>
<span><span class="fu">cramer.test</span><span class="op">(</span><span class="va">x</span>, <span class="va">ref.dat</span><span class="op">)</span></span>
<span><span class="co">#&gt; $p.value</span></span>
<span><span class="co">#&gt; [1] 0.149</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; $cramer.stat</span></span>
<span><span class="co">#&gt; [1] 0.112</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; $obs.size</span></span>
<span><span class="co">#&gt; [1] 100</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; $ref.size</span></span>
<span><span class="co">#&gt; [1] 1000000</span></span></code></pre></div>
<p>They are both compatible with the data. However, the Weibull
distribution has a larger
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>p</mi><annotation encoding="application/x-tex">p</annotation></semantics></math>-value,
which may suggest it is a better fit. We also have the AIC measure of
goodness of fit. The AIC is given by
<math display="block" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mtext mathvariant="normal">AIC</mtext><mo>=</mo><mo>‚àí</mo><mn>2</mn><mo>log</mo><mi>L</mi><mo>+</mo><mn>2</mn><mi>k</mi><mo>,</mo></mrow><annotation encoding="application/x-tex">
  \text{AIC} = -2\log L + 2k,
</annotation></semantics></math> where
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>L</mi><annotation encoding="application/x-tex">L</annotation></semantics></math>
is the likelihood of the model and
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>k</mi><annotation encoding="application/x-tex">k</annotation></semantics></math>
is the number of parameters in the model. The AIC is a measure of the
tradeoff between the goodness of fit and the complexity of the
model.</p>
<div class="sourceCode" id="cb18"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu"><a href="../reference/aic.html">aic</a></span><span class="op">(</span><span class="va">theta.weibull</span><span class="op">)</span></span>
<span><span class="co">#&gt; [1] 573</span></span>
<span><span class="fu"><a href="../reference/aic.html">aic</a></span><span class="op">(</span><span class="va">theta.hat</span><span class="op">)</span></span>
<span><span class="co">#&gt; [1] 583</span></span></code></pre></div>
<p>A lower AIC value indicates a better fit. Thus, according to this
measure, the Weibull distribution is the better fit.</p>
</div>
<div class="section level2">
<h2 id="prediction-intervals">Prediction Intervals<a class="anchor" aria-label="anchor" href="#prediction-intervals"></a>
</h2>
<p>Frequently, we are actually interested in predicting the outcome of
the random variable (or vector) that we are estimating the parameters
of.</p>
<p>We observed a sample
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>ùíü</mi><mo>=</mo><mo stretchy="false" form="prefix">{</mo><msub><mi>T</mi><mi>i</mi></msub><msubsup><mo stretchy="false" form="postfix">}</mo><mrow><mi>i</mi><mo>=</mo><mn>1</mn></mrow><mi>n</mi></msubsup></mrow><annotation encoding="application/x-tex">\mathcal{D} = \{T_i\}_{i=1}^n</annotation></semantics></math>
where
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>T</mi><mi>i</mi></msub><mo>‚àº</mo><mi>N</mi><mrow><mo stretchy="true" form="prefix">(</mo><mi>Œº</mi><mo>,</mo><msup><mi>œÉ</mi><mn>2</mn></msup><mo stretchy="true" form="postfix">)</mo></mrow></mrow><annotation encoding="application/x-tex">T_i \sim N(\mu,\sigma^2)</annotation></semantics></math>,
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>Œ∏</mi><mo>=</mo><msup><mrow><mo stretchy="true" form="prefix">(</mo><mi>Œº</mi><mo>,</mo><msup><mi>œÉ</mi><mn>2</mn></msup><mo stretchy="true" form="postfix">)</mo></mrow><mi>T</mi></msup></mrow><annotation encoding="application/x-tex">\theta = (\mu,\sigma^2)^T</annotation></semantics></math>
is not known. We compute the MLE of
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>Œ∏</mi><annotation encoding="application/x-tex">\theta</annotation></semantics></math>,
which, asymptotically, is normally distributed with a mean
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>Œ∏</mi><annotation encoding="application/x-tex">\theta</annotation></semantics></math>
and a variance-covariance
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msup><mi>I</mi><mrow><mo>‚àí</mo><mn>1</mn></mrow></msup><mrow><mo stretchy="true" form="prefix">(</mo><mi>Œ∏</mi><mo stretchy="true" form="postfix">)</mo></mrow><mi>/</mi><mi>n</mi></mrow><annotation encoding="application/x-tex">I^{-1}(\theta)/n</annotation></semantics></math>.</p>
<p>We wish to model the uncertainty of a new observation,
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mover><mi>T</mi><mo accent="true">ÃÇ</mo></mover><mrow><mi>n</mi><mo>+</mo><mn>1</mn></mrow></msub><mo stretchy="false" form="prefix">|</mo><mi>ùíü</mi></mrow><annotation encoding="application/x-tex">\hat{T}_{n+1}|\mathcal{D}</annotation></semantics></math>.
We do so by considering both the uncertainty inherent to the Normal
distribution and the uncertainty of our estimate
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mover><mi>Œ∏</mi><mo accent="true">ÃÇ</mo></mover><annotation encoding="application/x-tex">\hat\theta</annotation></semantics></math>
of
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>Œ∏</mi><annotation encoding="application/x-tex">\theta</annotation></semantics></math>.
In particular, we let
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mover><mi>T</mi><mo accent="true">ÃÇ</mo></mover><mrow><mi>n</mi><mo>+</mo><mn>1</mn></mrow></msub><mo stretchy="false" form="prefix">|</mo><mover><mi>Œ∏</mi><mo accent="true">ÃÇ</mo></mover><mo>‚àº</mo><mi>N</mi><mrow><mo stretchy="true" form="prefix">(</mo><mover><mi>Œº</mi><mo accent="true">ÃÇ</mo></mover><mo>,</mo><msup><mover><mi>œÉ</mi><mo accent="true">ÃÇ</mo></mover><mn>2</mn></msup><mo stretchy="true" form="postfix">)</mo></mrow></mrow><annotation encoding="application/x-tex">\hat{T}_{n+1}|\hat\theta \sim N(\hat\mu,\hat\sigma^2)</annotation></semantics></math>
and
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mover><mi>Œ∏</mi><mo accent="true">ÃÇ</mo></mover><mo>‚àº</mo><mi>N</mi><mrow><mo stretchy="true" form="prefix">(</mo><mi>Œ∏</mi><mo>,</mo><msup><mi>I</mi><mrow><mo>‚àí</mo><mn>1</mn></mrow></msup><mrow><mo stretchy="true" form="prefix">(</mo><mi>Œ∏</mi><mo stretchy="true" form="postfix">)</mo></mrow><mi>/</mi><mi>n</mi><mo stretchy="true" form="postfix">)</mo></mrow></mrow><annotation encoding="application/x-tex">\hat\theta \sim N(\theta,I^{-1}(\theta)/n)</annotation></semantics></math>
(the sampling distribution of the MLE). Then, the joint distribution of
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><msub><mover><mi>T</mi><mo accent="true">ÃÇ</mo></mover><mrow><mi>n</mi><mo>+</mo><mn>1</mn></mrow></msub><annotation encoding="application/x-tex">\hat{T}_{n+1}</annotation></semantics></math>
and
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mover><mi>Œ∏</mi><mo accent="true">ÃÇ</mo></mover><annotation encoding="application/x-tex">\hat\theta</annotation></semantics></math>
has the pdf given by
<math display="block" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>f</mi><mrow><mo stretchy="true" form="prefix">(</mo><mi>t</mi><mo>,</mo><mi>Œ∏</mi><mo stretchy="true" form="postfix">)</mo></mrow><mo>=</mo><msub><mi>f</mi><mrow><mover><mi>T</mi><mo accent="true">ÃÇ</mo></mover><mo stretchy="false" form="prefix">|</mo><mover><mi>Œ∏</mi><mo accent="true">ÃÇ</mo></mover></mrow></msub><mrow><mo stretchy="true" form="prefix">(</mo><mi>t</mi><mo stretchy="false" form="prefix">|</mo><mi>Œ∏</mi><mo>=</mo><mrow><mo stretchy="true" form="prefix">(</mo><mi>Œº</mi><mo>,</mo><msup><mi>œÉ</mi><mn>2</mn></msup><mo stretchy="true" form="postfix">)</mo></mrow><mo stretchy="true" form="postfix">)</mo></mrow><msub><mi>f</mi><mover><mi>Œ∏</mi><mo accent="true">ÃÇ</mo></mover></msub><mrow><mo stretchy="true" form="prefix">(</mo><mi>Œ∏</mi><mo stretchy="true" form="postfix">)</mo></mrow><mo>,</mo></mrow><annotation encoding="application/x-tex">
    f(t,\theta) = f_{\hat{T}|\hat\theta}(t|\theta=(\mu,\sigma^2)) f_{\hat\theta}(\theta),
</annotation></semantics></math> and thus to find
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>f</mi><mrow><mo stretchy="true" form="prefix">(</mo><mi>t</mi><mo stretchy="true" form="postfix">)</mo></mrow></mrow><annotation encoding="application/x-tex">f(t)</annotation></semantics></math>,
we marginalize over
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>Œ∏</mi><annotation encoding="application/x-tex">\theta</annotation></semantics></math>,
obtaining
<math display="block" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>f</mi><mrow><mo stretchy="true" form="prefix">(</mo><mi>t</mi><mo stretchy="true" form="postfix">)</mo></mrow><mo>=</mo><msubsup><mo>‚à´</mo><mrow><mo>‚àí</mo><mi>‚àû</mi></mrow><mi>‚àû</mi></msubsup><msubsup><mo>‚à´</mo><mrow><mo>‚àí</mo><mi>‚àû</mi></mrow><mi>‚àû</mi></msubsup><msub><mi>f</mi><mrow><msub><mover><mi>T</mi><mo accent="true">ÃÇ</mo></mover><mrow><mi>n</mi><mo>+</mo><mn>1</mn></mrow></msub><mo>,</mo><mover><mi>Œº</mi><mo accent="true">ÃÇ</mo></mover><mo>,</mo><msup><mover><mi>œÉ</mi><mo accent="true">ÃÇ</mo></mover><mn>2</mn></msup></mrow></msub><mrow><mo stretchy="true" form="prefix">(</mo><mi>t</mi><mo>,</mo><mi>Œº</mi><mo>,</mo><msup><mi>œÉ</mi><mn>2</mn></msup><mo stretchy="true" form="postfix">)</mo></mrow><mi>d</mi><mi>Œº</mi><mi>d</mi><msup><mi>œÉ</mi><mn>2</mn></msup><mi>.</mi></mrow><annotation encoding="application/x-tex">
    f(t) = \int_{-\infty}^\infty \int_{-\infty}^{\infty} f_{\hat{T}_{n+1},\hat\mu,\hat\sigma^2}(t,\mu,\sigma^2) d\mu d\sigma^2.
</annotation></semantics></math></p>
<p>Given the information in the sample, the uncertainty in the new
observation is characterized by the distribution
<math display="block" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mover><mi>T</mi><mo accent="true">ÃÇ</mo></mover><mrow><mi>n</mi><mo>+</mo><mn>1</mn></mrow></msub><mo>‚àº</mo><mi>f</mi><mrow><mo stretchy="true" form="prefix">(</mo><mi>t</mi><mo stretchy="true" form="postfix">)</mo></mrow><mi>.</mi></mrow><annotation encoding="application/x-tex">
    \hat{T}_{n+1} \sim f(t).
</annotation></semantics></math></p>
<p>It has greater variance than
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>T</mi><mrow><mi>n</mi><mo>+</mo><mn>1</mn></mrow></msub><mo stretchy="false" form="prefix">|</mo><mover><mi>Œ∏</mi><mo accent="true">ÃÇ</mo></mover></mrow><annotation encoding="application/x-tex">T_{n+1}|\hat\theta</annotation></semantics></math>
because, as stated earlier, we do not know
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>Œ∏</mi><annotation encoding="application/x-tex">\theta</annotation></semantics></math>,
we only have an uncertain estimate
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mover><mi>Œ∏</mi><mo accent="true">ÃÇ</mo></mover><annotation encoding="application/x-tex">\hat\theta</annotation></semantics></math>.</p>
<p>In <code>pred</code>, we compute the predictive interval (PI) of the
distribution of
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><msub><mover><mi>T</mi><mo accent="true">ÃÇ</mo></mover><mrow><mi>n</mi><mo>+</mo><mn>1</mn></mrow></msub><annotation encoding="application/x-tex">\hat{T}_{n+1}</annotation></semantics></math>
using Monte Carlo simulation, where we replace the integral with a sum
over a large number of draws from the joint distribution of
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><msub><mover><mi>T</mi><mo accent="true">ÃÇ</mo></mover><mrow><mi>n</mi><mo>+</mo><mn>1</mn></mrow></msub><annotation encoding="application/x-tex">\hat{T}_{n+1}</annotation></semantics></math>
and
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mover><mi>Œ∏</mi><mo accent="true">ÃÇ</mo></mover><annotation encoding="application/x-tex">\hat\theta</annotation></semantics></math>
and then compute the empirical quantiles.</p>
<p>The function <code>pred</code> takes as arguments <code>x</code>, in
this case an <code>mle</code> object, and a sampler for the distribution
of the random variable of interest, in this case <code>rweibull</code>
(the sampler for the normal distribution). The sampler must be
compatible with the output of <code>point(x)</code>, whether that output
be a scalar or a vector. Here is how we compute the PI for
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><msub><mover><mi>T</mi><mo accent="true">ÃÇ</mo></mover><mrow><mi>n</mi><mo>+</mo><mn>1</mn></mrow></msub><annotation encoding="application/x-tex">\hat{T}_{n+1}</annotation></semantics></math>:</p>
<div class="sourceCode" id="cb19"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu"><a href="../reference/pred.html">pred</a></span><span class="op">(</span>x<span class="op">=</span><span class="va">theta.hat</span>, samp<span class="op">=</span><span class="kw">function</span><span class="op">(</span><span class="va">n</span><span class="op">=</span><span class="fl">1</span>, <span class="va">theta</span><span class="op">)</span> <span class="fu"><a href="https://rdrr.io/r/stats/Normal.html" class="external-link">rnorm</a></span><span class="op">(</span><span class="va">n</span>,<span class="va">theta</span><span class="op">[</span><span class="fl">1</span><span class="op">]</span>,<span class="va">theta</span><span class="op">[</span><span class="fl">2</span><span class="op">]</span><span class="op">)</span><span class="op">)</span></span>
<span><span class="co">#&gt;      mean lower upper</span></span>
<span><span class="co">#&gt; [1,] 8.39 -29.8  46.6</span></span></code></pre></div>
<p>In general, it will return a
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>p</mi><annotation encoding="application/x-tex">p</annotation></semantics></math>-by-<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mn>3</mn><annotation encoding="application/x-tex">3</annotation></semantics></math>
matrix, where
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>p</mi><annotation encoding="application/x-tex">p</annotation></semantics></math>
is the dimension of
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>T</mi><annotation encoding="application/x-tex">T</annotation></semantics></math>
and the columns are the mean, lower quantile, and upper quantile of the
predictive distribution.</p>
<p>How does this compare to
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>T</mi><mrow><mi>n</mi><mo>+</mo><mn>1</mn></mrow></msub><mo stretchy="false" form="prefix">|</mo><mover><mi>Œ∏</mi><mo accent="true">ÃÇ</mo></mover></mrow><annotation encoding="application/x-tex">T_{n+1}|\hat\theta</annotation></semantics></math>?
We can compute the 95% quantile interval for
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>T</mi><mrow><mi>n</mi><mo>+</mo><mn>1</mn></mrow></msub><mo stretchy="false" form="prefix">|</mo><mover><mi>Œ∏</mi><mo accent="true">ÃÇ</mo></mover></mrow><annotation encoding="application/x-tex">T_{n+1}|\hat\theta</annotation></semantics></math>
using the <code>qnorm</code> function:</p>
<div class="sourceCode" id="cb20"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">mu</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://queelius.github.io/algebraic.dist/reference/params.html" class="external-link">params</a></span><span class="op">(</span><span class="va">theta.hat</span><span class="op">)</span><span class="op">[</span><span class="fl">1</span><span class="op">]</span></span>
<span><span class="va">sd</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/MathFun.html" class="external-link">sqrt</a></span><span class="op">(</span><span class="fu"><a href="https://queelius.github.io/algebraic.dist/reference/params.html" class="external-link">params</a></span><span class="op">(</span><span class="va">theta.hat</span><span class="op">)</span><span class="op">[</span><span class="fl">2</span><span class="op">]</span><span class="op">)</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/base/c.html" class="external-link">c</a></span><span class="op">(</span>mean<span class="op">=</span><span class="va">mu</span>,lower<span class="op">=</span><span class="fu"><a href="https://rdrr.io/r/stats/Normal.html" class="external-link">qnorm</a></span><span class="op">(</span><span class="fl">.025</span>,mean<span class="op">=</span><span class="va">mu</span>, sd<span class="op">=</span><span class="va">sd</span><span class="op">)</span>,upper<span class="op">=</span><span class="fu"><a href="https://rdrr.io/r/stats/Normal.html" class="external-link">qnorm</a></span><span class="op">(</span><span class="fl">.975</span>,mean<span class="op">=</span><span class="va">mu</span>, sd<span class="op">=</span><span class="va">sd</span><span class="op">)</span><span class="op">)</span></span>
<span><span class="co">#&gt;   mean  lower  upper </span></span>
<span><span class="co">#&gt;  8.230 -0.338 16.799</span></span></code></pre></div>
<p>We see that the 95% quantile interval for
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>T</mi><mrow><mi>n</mi><mo>+</mo><mn>1</mn></mrow></msub><mo stretchy="false" form="prefix">|</mo><mover><mi>Œ∏</mi><mo accent="true">ÃÇ</mo></mover></mrow><annotation encoding="application/x-tex">T_{n+1}|\hat\theta</annotation></semantics></math>
is smaller than
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><msub><mover><mi>T</mi><mo accent="true">ÃÇ</mo></mover><mrow><mi>n</mi><mo>+</mo><mn>1</mn></mrow></msub><annotation encoding="application/x-tex">\hat{T}_{n+1}</annotation></semantics></math>,
which is what we expected. After all, there is uncertainty about the
parameter value
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>Œ∏</mi><annotation encoding="application/x-tex">\theta</annotation></semantics></math>.</p>
</div>
<div class="section level2">
<h2 id="conclusion">Conclusion<a class="anchor" aria-label="anchor" href="#conclusion"></a>
</h2>
<p>In this vignette, we demonstrated how to use the
<code>algebraic.mle</code> package to estimate the sampling distribution
of the MLE using the large sampling assumption and the Bootstrap method.
The package provides various functions for obtaining statistics of the
MLE, allowing for a deeper understanding of the properties of your
estimator.</p>
<p>We showed how to fit Weibull and Normal distributions to a simulated
dataset whose true distribution, while known, does not have a common
name.</p>
<p>We have shown how to compare the two models using the Cramer-von
Mises test and the AIC measure of goodness of fit. We came to no
definitive conclusion about which model is better, but the Weibull
distribution has a larger
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>p</mi><annotation encoding="application/x-tex">p</annotation></semantics></math>-value
from the Cramer-von Mises test, and a lower AIC value, which serves as
some evidence that it is a better fit. We saw the true DGP is visually
different from both the Weibull and the normal distributions. Notably,
the DGP has longer tails than both, suggesting that an even better fit
may be a long-tail distribution like the log-normal or the Pareto
distribution.</p>
</div>
  </main><aside class="col-md-3"><nav id="toc" aria-label="Table of contents"><h2>On this page</h2>
    </nav></aside>
</div>



    <footer><div class="pkgdown-footer-left">
  <p>Developed by Alexander Towell.</p>
</div>

<div class="pkgdown-footer-right">
  <p>Site built with <a href="https://pkgdown.r-lib.org/" class="external-link">pkgdown</a> 2.2.0.</p>
</div>

    </footer>
</div>





  </body>
</html>
